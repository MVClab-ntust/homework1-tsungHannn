{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0+cu121\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 把官網下載的batch轉成圖片\n",
    "# # 要先把batches.meta跟readme.html拿走\n",
    "# def unpickle(file):\n",
    "#     with open(file, 'rb') as fo:\n",
    "#         dict = pickle.load(fo, encoding='bytes')\n",
    "#     return dict[b'labels'], dict[b'filenames'], dict[b'data']\n",
    "\n",
    "\n",
    "# with open(\"batches.meta\", 'rb') as file:\n",
    "#     matadata = pickle.load(file, encoding='bytes')\n",
    "#     # print(dict)\n",
    "\n",
    "# labelName = matadata[b'label_names']\n",
    "# for i in range(len(labelName)):\n",
    "#     labelName[i] = labelName[i].decode('utf-8')\n",
    "\n",
    "\n",
    "# for path in os.listdir('cifar-10-batches-py'):\n",
    "#     print(\"Extract: \", path)\n",
    "#     labels,names, datas = unpickle(f'cifar-10-batches-py/{path}')\n",
    "    \n",
    "#     for label, name, data in zip(labels,names,datas):\n",
    "#         try:\n",
    "#             os.makedirs(f'pic/train/{labelName[label]}')\n",
    "#             os.makedirs(f'pic/test/{labelName[label]}')\n",
    "#         except:\n",
    "#             pass\n",
    "            \n",
    "#         R = data[:1024]\n",
    "#         G = data[1024:2048]\n",
    "#         B = data[2048:3072]\n",
    "        \n",
    "#         img,tmp = [],[]\n",
    "#         for cnt,(r,g,b) in enumerate(zip(R,G,B),1):\n",
    "#             tmp.append([b, g, r])\n",
    "#             if cnt % 32 == 0:\n",
    "#                 img.append(tmp)\n",
    "#                 tmp = []\n",
    "              \n",
    "#         if path == 'test_batch':\n",
    "#             cv2.imwrite(f'pic/test/{labelName[label]}/{str(name)[2:-1]}', np.array(img))\n",
    "#         else:\n",
    "#             cv2.imwrite(f'pic/train/{labelName[label]}/{str(name)[2:-1]}', np.array(img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, stride):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        # Convolution -> Batch Normalization -> ReLu\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=in_channel, out_channels=out_channel, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(num_features=out_channel)\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=out_channel, out_channels=out_channel, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(num_features=out_channel)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = torch.nn.functional.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out += residual # 加上原本的 -> Residual\n",
    "        out = torch.nn.functional.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 跟ResidualBlock一樣，但是要降tensor的大小 -> stride要改\n",
    "class DownBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, stride):\n",
    "        super(DownBlock, self).__init__()\n",
    "        # 兩層convolution\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=in_channel, out_channels=out_channel, kernel_size=3, stride=stride[0], padding=1)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(num_features=out_channel)\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=out_channel, out_channels=out_channel, kernel_size=3, stride=stride[1], padding=1)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(num_features=out_channel)\n",
    "        self.adjustChannel = torch.nn.Conv2d(in_channels=in_channel, out_channels=out_channel, kernel_size=1, stride=stride[0])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        residual = self.adjustChannel(residual)\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = torch.nn.functional.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += residual # 加上原本的 -> Residual\n",
    "        out = torch.nn.functional.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ResNet18(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18, self).__init__()\n",
    "        # conv1, conv2, conv3... 對照ResNet18_architecture.png命名\n",
    "        \n",
    "        # channel x W x H\n",
    "        # output size = (W - kernel_size + 2 *padding) / stride\n",
    "\n",
    "        # input: 3x32x32\n",
    "        # output: 64x16x16\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=3, out_channels=64, stride=2, kernel_size=7, padding=3)\n",
    "\n",
    "        # input: 64x16x16\n",
    "        # output: 64x8x8\n",
    "        self.maxPool = torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # input: 64x8x8\n",
    "        # output: 64x8x8\n",
    "        self.conv2 = torch.nn.Sequential(ResidualBlock(64, 64, 1),\n",
    "                                         ResidualBlock(64, 64, 1))\n",
    "        \n",
    "        # input: 64x8x8\n",
    "        # output: 128x4x4\n",
    "        self.conv3 = torch.nn.Sequential(DownBlock(64, 128, [2, 1]),\n",
    "                                         ResidualBlock(128, 128, 1))\n",
    "        \n",
    "        # input: 128x4x4\n",
    "        # output: 256x2x2\n",
    "        self.conv4 = torch.nn.Sequential(DownBlock(128, 256, [2, 1]),\n",
    "                                         ResidualBlock(256, 256, 1))\n",
    "        \n",
    "        # input: 256x2x2\n",
    "        # output: 512x1x1\n",
    "        self.conv5 = torch.nn.Sequential(DownBlock(256, 512, [2, 1]),\n",
    "                                         ResidualBlock(512, 512, 1))\n",
    "        \n",
    "        # input: 512x1x1\n",
    "        # output: 512x1x1\n",
    "        self.averagePool = torch.nn.AdaptiveAvgPool2d(output_size=(1,1))\n",
    "\n",
    "        # input: 512x1x1\n",
    "        # output: 10\n",
    "        self.fc = torch.nn.Linear(in_features=512, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.maxPool(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.conv5(out)\n",
    "        out = self.averagePool(out)\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil2tensor(img):\n",
    "    transform = torchvision.transforms.ToTensor()\n",
    "    result = transform(img)\n",
    "    return result\n",
    "\n",
    "def int2tensor(number):\n",
    "    result = torch.tensor(int(number))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 3125/3125 [00:28<00:00, 108.67it/s, Loss=1.65]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss: 1.7087956666946411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 3125/3125 [00:28<00:00, 109.12it/s, Loss=1.27]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loss: 1.3590224981307983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 3125/3125 [00:28<00:00, 109.49it/s, Loss=1.04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 loss: 0.9670544862747192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 3125/3125 [00:28<00:00, 108.87it/s, Loss=0.898]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 loss: 0.6400479078292847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 3125/3125 [00:28<00:00, 108.75it/s, Loss=0.787]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 loss: 0.39349785447120667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 3125/3125 [00:28<00:00, 108.69it/s, Loss=0.698]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 loss: 0.6929441690444946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 3125/3125 [00:28<00:00, 108.72it/s, Loss=0.609]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 loss: 0.5729960203170776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 3125/3125 [00:28<00:00, 108.56it/s, Loss=0.539]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 loss: 1.2785305976867676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3125/3125 [00:28<00:00, 108.53it/s, Loss=0.469]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 loss: 1.1779543161392212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 3125/3125 [00:28<00:00, 108.74it/s, Loss=0.407]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 loss: 0.49165794253349304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# main\n",
    "cifar_train = ImageFolder(root=\"pic/train\", transform=pil2tensor, target_transform=int2tensor)\n",
    "cifar_test = ImageFolder(root=\"pic/test\", transform=pil2tensor, target_transform=int2tensor)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(cifar_train, batch_size=16,shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(cifar_test, batch_size=16, shuffle=False, num_workers=2)\n",
    "\n",
    "device = torch.device('cuda')\n",
    "model = ResNet18().to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    data_loader = tqdm(trainloader, desc=f\"Epoch {epoch+1}\", leave=True)  # leave=False: 結束後進度條不會消失\n",
    "    for idx, (x, label) in enumerate(data_loader):\n",
    "        x, label = x.to(device), label.to(device)\n",
    "        \n",
    "        result = model(x)\n",
    "        loss = criterion(result, label)\n",
    "\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        data_loader.set_postfix({'Loss': epoch_loss / (idx + 1)})\n",
    "    \n",
    "    print(epoch, \"loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test the Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test: 100%|██████████| 625/625 [00:02<00:00, 238.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 40 % Number: 10000\n",
      "\n",
      "Accuracy of plane : 39 % Number: 1000.0\n",
      "Accuracy of   car : 52 % Number: 1000.0\n",
      "Accuracy of  bird : 35 % Number: 1000.0\n",
      "Accuracy of   cat : 25 % Number: 1000.0\n",
      "Accuracy of  deer : 31 % Number: 1000.0\n",
      "Accuracy of   dog : 35 % Number: 1000.0\n",
      "Accuracy of  frog : 53 % Number: 1000.0\n",
      "Accuracy of horse : 43 % Number: 1000.0\n",
      "Accuracy of  ship : 42 % Number: 1000.0\n",
      "Accuracy of truck : 44 % Number: 1000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Test the Model\")\n",
    "data_loader = tqdm(testloader, desc=f\"test\", leave=True)  # leave=False: 結束後進度條不會消失\n",
    "\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "total = 0\n",
    "total_correct = 0\n",
    "with torch.no_grad():\n",
    "    for data in data_loader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(16):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "            total_correct += c[i].item()\n",
    "            total +=1\n",
    "\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * total_correct / total), \"Number:\", total)\n",
    "print()\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]), \"Number:\", class_total[i])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
